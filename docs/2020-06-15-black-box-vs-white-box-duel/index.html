<!DOCTYPE html>
<html lang="en">

<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
<meta name="HandheldFriendly" content="True" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<meta name="generator" content="Hugo 0.72.0" />



<link rel="apple-touch-icon" sizes="180x180" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon-16x16.png" />
<link rel="manifest" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/site.webmanifest" />
<link rel="mask-icon" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/safari-pinned-tab.svg" color="#8aa2d3" />
<link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon.ico" />
<meta name="msapplication-TileColor" content="#8aa2d3" />
<meta name="msapplication-config" content="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/browserconfig.xml" />
<meta name="theme-color" content="#ffffff" />



<title>Black-box VS White-box Duel - Machine Learning Case Studies</title>

<meta name="author" content="" />
<meta name="description" content="Prepare to fight The interpretability of machine learning models is gaining more and more interest in the scientific world. It’s because artificial intelligence is used in a lot of business solutions that impact our everyday life. Knowledge how the model works can, among others, assure us about the safety of the implemented solution. We came across the article of students of the Warsaw University of Technology Wojciech Bogucki, Tomasz Makowski, Dominik Rafacz titled “Predicting code defects using interpretable static measures.” touching this topic.
Black box vs white box Using interpretable models, such as linear regression, decision trees and k-nearest neighbors is one way to have your solution explainable." />

<meta name="keywords" content="Interpretability, Machine Learning, XAI" />

<meta property="og:title" content="Black-box VS White-box Duel" />
<meta property="og:description" content="Prepare to fight The interpretability of machine learning models is gaining more and more interest in the scientific world. It’s because artificial intelligence is used in a lot of business solutions that impact our everyday life. Knowledge how the model works can, among others, assure us about the safety of the implemented solution. We came across the article of students of the Warsaw University of Technology Wojciech Bogucki, Tomasz Makowski, Dominik Rafacz titled “Predicting code defects using interpretable static measures.” touching this topic.
Black box vs white box Using interpretable models, such as linear regression, decision trees and k-nearest neighbors is one way to have your solution explainable." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/2020L-WB-Blog/2020-06-15-black-box-vs-white-box-duel/" />
<meta property="og:image" content="/2020L-WB-Blog/img/og.png"/>
<meta property="article:published_time" content="2020-06-15T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-06-15T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/2020L-WB-Blog/img/og.png"/>

<meta name="twitter:title" content="Black-box VS White-box Duel"/>
<meta name="twitter:description" content="Prepare to fight The interpretability of machine learning models is gaining more and more interest in the scientific world. It’s because artificial intelligence is used in a lot of business solutions that impact our everyday life. Knowledge how the model works can, among others, assure us about the safety of the implemented solution. We came across the article of students of the Warsaw University of Technology Wojciech Bogucki, Tomasz Makowski, Dominik Rafacz titled “Predicting code defects using interpretable static measures.” touching this topic.
Black box vs white box Using interpretable models, such as linear regression, decision trees and k-nearest neighbors is one way to have your solution explainable."/>






<link rel="stylesheet" href="/2020L-WB-Blog/css/main.min.css" />



<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.0/dist/jquery.min.js" integrity="sha256-xNzN2a4ltkB44Mc/Jz3pT4iU1cmeR0FkXs4pru/JxaQ=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.0/lazysizes.min.js" integrity="sha256-h2tMEmhemR2IN4wbbdNjj9LaDIjzwk2hralQwfJmBOE=" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css" integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous" />
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.5/dist/medium-zoom.min.js" integrity="sha256-Jd9xef1tT52aCb+cAqhElj/9D3c99lQvEjyKOuPn3S4=" crossorigin="anonymous"></script>







<body class="d-flex flex-column h-100">
    <header>
    <div class="container-lg clearfix">
        <div class="col-12 link-primary">
            <a class="main-title" href="/2020L-WB-Blog/">Machine Learning Case Studies</a>
            
            <span class="sub-title">by Evidence Based Machine Learning Lab</span>
            
        </div>
    </div>
</header>

    <main>
        <div class="container-lg clearfix">
            
            <div class="col-md-9 col-12 float-left" id="content">
                
<article>
    
    <h4 class="post-title">
        <a href="/2020L-WB-Blog/2020-06-15-black-box-vs-white-box-duel/">Black-box VS White-box Duel</a>
    </h4>
    <div>
        <span>
            
                Bartłomiej Eljasiak;
            
                Konrad Komisarczyk;
            
                Mariusz Słapek;
            
        </span>
    </div>
    <div class="post-meta link-alter">
        <time><i class="fas fa-calendar-day"></i>&nbsp;2020-06-15</time><span><i class="fas fa-file-alt"></i>&nbsp;757 words</span><span><i class="fas fa-tag"></i>&nbsp;<a href="/tags/interpretability/">Interpretability</a> <a href="/tags/machine-learning/">Machine Learning</a> <a href="/tags/xai/">XAI</a> </span>
    </div>
    
    
    <div class="post-content markdown-body">
        <h2 id="prepare-to-fight">Prepare to fight</h2>
<p>The interpretability of machine learning models is gaining more and more interest in the scientific world. It’s because artificial intelligence is used in a lot of business solutions that impact our everyday life. Knowledge how the model works can, among others, assure us about the safety of the implemented solution. We came across the article of students of the Warsaw University of Technology Wojciech Bogucki, Tomasz Makowski, Dominik Rafacz titled “Predicting code defects using interpretable static measures.” touching this topic.</p>
<p><img src="/2020L-WB-Blog/2020-06-15-black-box-vs-white-box-duel/black-vs-white.png" alt=""></p>
<h2 id="black-box-vs-white-box">Black box vs white box</h2>
<p>Using interpretable models, such as linear regression, decision trees and k-nearest neighbors is one way to have your solution explainable. Authors of the discussed article checked if applying different transformations to the dataset can help white-box models outperform black-box models. They were trying to predict code defects of C and C++ functions basing on the dataset describing the functions in terms of simple measures, like for example length of the code and number of operands. The Black-box model they were trying to beat was random forest with default hyperparameters.</p>
<h2 id="exchange-of-blows">Exchange of blows</h2>
<p>They were trying to improve their white-box models of choice in consecutive stages. In every stage, they compared results of applying several upgrades of similar character to their solutions and then decided whether to keep any of them. Every step of this work is presented in the table below:</p>
<table>
<thead>
<tr>
<th>Order</th>
<th>Applied operation</th>
<th>logreg</th>
<th>kknn</th>
<th>rpart</th>
<th>Kept?</th>
</tr>
</thead>
<tbody>
<tr>
<td>-</td>
<td>Base</td>
<td>$0.735$</td>
<td>$0.728$</td>
<td>$0.500$</td>
<td>-</td>
</tr>
<tr>
<td>0</td>
<td><code>rpart</code> tuning</td>
<td>$0.735$</td>
<td>$0.728$</td>
<td>$0.737$</td>
<td><strong>yes</strong></td>
</tr>
<tr>
<td>1a</td>
<td>Normalization</td>
<td>$0.735$</td>
<td>$0.727$</td>
<td>$0.737$</td>
<td>no</td>
</tr>
<tr>
<td>1b</td>
<td>Outlier reduction</td>
<td>$0.743$</td>
<td>$0.732$</td>
<td>$0.739$</td>
<td>no</td>
</tr>
<tr>
<td>1c</td>
<td>Logarithm</td>
<td>$0.744$</td>
<td>$0.718$</td>
<td>$0.725$</td>
<td>no</td>
</tr>
<tr>
<td>2a</td>
<td>Outlier reduction and normalization</td>
<td>$0.743$</td>
<td>$0.732$</td>
<td>$0.739$</td>
<td><strong>yes</strong></td>
</tr>
<tr>
<td>2b</td>
<td>Logarithm and outlier reduction</td>
<td>$0.744$</td>
<td>$0.717$</td>
<td>$0.725$</td>
<td>no</td>
</tr>
<tr>
<td>3a</td>
<td>Gain-ratio discretization</td>
<td>$0.743$</td>
<td>$0.732$</td>
<td>$0.739$</td>
<td>no</td>
</tr>
<tr>
<td>3b</td>
<td><code>rSAFE</code></td>
<td>$0.744$</td>
<td>$0.718$</td>
<td>$0.734$</td>
<td>no</td>
</tr>
<tr>
<td>4a</td>
<td>New features selected by <code>ranger</code></td>
<td>$0.747$</td>
<td>$0.729$</td>
<td>$0.733$</td>
<td>no</td>
</tr>
<tr>
<td>4b</td>
<td>New features selected by <code>rpart</code></td>
<td>$0.745$</td>
<td>$0.731$</td>
<td>$0.739$</td>
<td>no</td>
</tr>
<tr>
<td>4c</td>
<td>Halstead&rsquo;s measures</td>
<td>$0.745$</td>
<td>$0.731$</td>
<td>$0.738$</td>
<td>no</td>
</tr>
<tr>
<td>5a</td>
<td><code>SMOTE</code> with new features by <code>ranger</code></td>
<td>$0.749$</td>
<td>$0.737$</td>
<td>$0.800$</td>
<td>no</td>
</tr>
<tr>
<td>5b</td>
<td><code>SMOTE</code> with new features by <code>rpart</code></td>
<td>$0.747$</td>
<td>$0.736$</td>
<td>$0.793$</td>
<td>no</td>
</tr>
<tr>
<td>5c</td>
<td><code>SMOTE</code> without new features</td>
<td>$0.745$</td>
<td>$0.736$</td>
<td>$0.804$</td>
<td><strong>yes</strong></td>
</tr>
</tbody>
</table>
<p>They decided to use AUC to assess the quality of models (values in columns logreg, kknn, rpart). The dataset was imbalanced (only 20% observations were code with defects) and AUC is not the most suitable for imbalanced data but according to authors 20%/80% still is not a tragedy. We wonder what would be if they used different measures, such as the Matthews correlation coefficient.</p>
<p>The first step they made was hyperparameter tuning of the decision tree. It produced the most drastic gain of all the steps. Before it, the decision tree was only as good as random assignment, and just after tuning it slightly overtaken other white-boxes. Maybe in the case of black-box random forest, tuning would have also brought a big improvement. Such a pity, the authors didn’t discuss it. Hyperparameter tuning does not need a lot of effort and is almost always done also with the random forest.</p>
<p>The authors also considered the discretization of columns as a way to improve results. Unfortunately, the techniques they used didn’t bring any improvement. Looking at the partial dependence plot produced with the DALEX package they concluded that there is no variable to be discretized, probably because of no linear dependency of variables.</p>
<p>An important part of their aim was to check whether Halstead’s and McCabe’s measures were reliable. Adding Halstead’s measures did not bring any significant improvement and so the authors concluded his hypothesis was wrong. They were not able to remove McCabe’s measures from the set and so were not able to test their validity. Maybe checking the importance of McCabe’s measures would be a good idea to check how they contribute to the result - how important they are compared to basic features and do they contribute in the same direction as their author intended to.</p>
<h2 id="fair-victory">Fair victory?</h2>
<p>Finally, the authors managed to upgrade the decision tree so it has beaten random forest. Although, the main thing contributing to this was hyperparameter tuning. The authors were rather not satisfied with this result.</p>
<p><img src="/2020L-WB-Blog/2020-06-15-black-box-vs-white-box-duel/result.png" alt=""></p>
<p>To sum up, in our opinion, it&rsquo;s a crucial topic and good that somebody is creating such things. It’s a pity that authors were not able to get more out of the dataset transformations, especially Halstead’s and McCabe’s measures. Questions, which are intriguing for us, are if they were able to beat random forest with tuned hyperparameters or other black-box models, such as XGBoost or LightGBM.</p>

    </div>
</article>


<div class="license markdown-body">
    <blockquote>
        <p>Unless otherwise noted, the content of this site is licensed under <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)</a>.</p>
    </blockquote>
</div>






            </div>
            
            <div class="col-md-3 col-12 float-left link-alter" id="sidebar">
                

<div class="widget-toc">
    <h5>TOC</h5>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#prepare-to-fight">Prepare to fight</a></li>
    <li><a href="#black-box-vs-white-box">Black box vs white box</a></li>
    <li><a href="#exchange-of-blows">Exchange of blows</a></li>
    <li><a href="#fair-victory">Fair victory?</a></li>
  </ul>
</nav>
</div>


<div class="widget-pages">
    <h5>Pages</h5>
    <ul>
        
        
        <li>
            <a href="/2020L-WB-Blog/">Home</a>
        </li>
        
        <li>
            <a href="/2020L-WB-Blog/archives/">Archives</a>
        </li>
        
        <li>
            <a href="/2020L-WB-Blog/about/">About</a>
        </li>
        
    </ul>
</div>

<div class="widget-tags">
    <h5>Tags</h5>
    <div>
        
        <span>
            <a href="/2020L-WB-Blog/tags/automated-regression/">automated regression</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/black-boxes/">black-boxes</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/computer-vision/">computer vision</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/dataset/">dataset</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/embedding/">embedding</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/imputation/">Imputation</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/interpretability/">interpretability</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/machine-learning/">Machine Learning</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/missing-data/">Missing data</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/missings/">missings</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/ml/">ML</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/openml/">OpenML</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/tutorial/">tutorial</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/xai/">XAI</a>
        </span>
        
    </div>
</div>

<div class="widget-links">
    <h5>Links</h5>
    <ul>
        
        <li>
            <a href="https://mini-pw.github.io/2020L-WB-Book/" target="_blank"><span>ML Case Studies Book</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-Reprodukowalnosc" target="_blank"><span>Reproducibility repo (in Polish)</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-Imputacja" target="_blank"><span>Imputation repo (in Polish)</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-InzynieriaCech" target="_blank"><span>Interpretability repo (in Polish)</span></a>
        </li>
        
    </ul>
</div>


            </div>
            
            
            
            <div id="scroll-top">
                <i class="fas fa-chevron-up"></i>
            </div>
            
        </div>
    </main>

    <footer>
    <div class="container-lg text-center">
        <p>&copy; 2020 <a href="/2020L-WB-Blog/"></a> | Powered by <a href="https://github.com/amzrk2/hugo-theme-fuji/" target="_blank">Fuji</a> & <a href="https://gohugo.io/" target="_blank">Hugo</a> </p>
    </div>
    <script src="//yihui.org/js/math-code.js"></script>
<script async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</footer>
    
<script>
    $(function () {
        mediumZoom('.img-zoomable', {
            margin: 32
        });
    });
</script>








<script>
    $('.widget-toc a').click(function () {
        $('html, body').animate({
            scrollTop: $($(this).attr('href')).offset().top
        });
    });
</script>



<script>
    $('#scroll-top').click(function () {
        $('html, body').animate({
            scrollTop: 0
        });
    });
</script>






</body>

</html>
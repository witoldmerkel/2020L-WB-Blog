<!DOCTYPE html>
<html lang="en">

<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
<meta name="HandheldFriendly" content="True" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<meta name="generator" content="Hugo 0.72.0" />



<link rel="apple-touch-icon" sizes="180x180" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon-16x16.png" />
<link rel="manifest" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/site.webmanifest" />
<link rel="mask-icon" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/safari-pinned-tab.svg" color="#8aa2d3" />
<link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon.ico" />
<meta name="msapplication-TileColor" content="#8aa2d3" />
<meta name="msapplication-config" content="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/browserconfig.xml" />
<meta name="theme-color" content="#ffffff" />



<title>Imputing missing data for a classification problem - Machine Learning Case Studies</title>

<meta name="author" content="" />
<meta name="description" content="Imputing missing data for a classification problem Authors: Karol Saputa, Małgorzata Wachulec, Aleksandra Wichrowska (Warsaw University of Technology)
As students of the same university course, we were asked to sum up the findings of our colleges, the authors of the Default imputation efficiency comparison article. In their work, they used many missing data imputation techniques on 11 datasets, on which they then run different classification algorithms. By measuring the results obtained using these imputation algorithms they could judge their performance. But first:
What is data imputation? Some datasets have missing values that many classification algorithms cannot handle. One way to make the algorithm work is to delete the observations that include missing data or, if missing values come just from a few columns, we can delete them instead." />

<meta name="keywords" content="imputation, missing data" />

<meta property="og:title" content="Imputing missing data for a classification problem" />
<meta property="og:description" content="Imputing missing data for a classification problem Authors: Karol Saputa, Małgorzata Wachulec, Aleksandra Wichrowska (Warsaw University of Technology)
As students of the same university course, we were asked to sum up the findings of our colleges, the authors of the Default imputation efficiency comparison article. In their work, they used many missing data imputation techniques on 11 datasets, on which they then run different classification algorithms. By measuring the results obtained using these imputation algorithms they could judge their performance. But first:
What is data imputation? Some datasets have missing values that many classification algorithms cannot handle. One way to make the algorithm work is to delete the observations that include missing data or, if missing values come just from a few columns, we can delete them instead." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/2020L-WB-Blog/2020-06-05-imputing-missing-data-for-a-classification-problem/" />
<meta property="og:image" content="/2020L-WB-Blog/img/og.png"/>
<meta property="article:published_time" content="2020-06-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-06-05T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/2020L-WB-Blog/img/og.png"/>

<meta name="twitter:title" content="Imputing missing data for a classification problem"/>
<meta name="twitter:description" content="Imputing missing data for a classification problem Authors: Karol Saputa, Małgorzata Wachulec, Aleksandra Wichrowska (Warsaw University of Technology)
As students of the same university course, we were asked to sum up the findings of our colleges, the authors of the Default imputation efficiency comparison article. In their work, they used many missing data imputation techniques on 11 datasets, on which they then run different classification algorithms. By measuring the results obtained using these imputation algorithms they could judge their performance. But first:
What is data imputation? Some datasets have missing values that many classification algorithms cannot handle. One way to make the algorithm work is to delete the observations that include missing data or, if missing values come just from a few columns, we can delete them instead."/>






<link rel="stylesheet" href="/2020L-WB-Blog/css/main.min.css" />



<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.0/dist/jquery.min.js" integrity="sha256-xNzN2a4ltkB44Mc/Jz3pT4iU1cmeR0FkXs4pru/JxaQ=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.0/lazysizes.min.js" integrity="sha256-h2tMEmhemR2IN4wbbdNjj9LaDIjzwk2hralQwfJmBOE=" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css" integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous" />
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.5/dist/medium-zoom.min.js" integrity="sha256-Jd9xef1tT52aCb+cAqhElj/9D3c99lQvEjyKOuPn3S4=" crossorigin="anonymous"></script>







<body class="d-flex flex-column h-100">
    <header>
    <div class="container-lg clearfix">
        <div class="col-12 link-primary">
            <a class="main-title" href="/2020L-WB-Blog/">Machine Learning Case Studies</a>
            
            <span class="sub-title">by Evidence Based Machine Learning Lab</span>
            
        </div>
    </div>
</header>

    <main>
        <div class="container-lg clearfix">
            
            <div class="col-md-9 col-12 float-left" id="content">
                
<article>
    
    <h4 class="post-title">
        <a href="/2020L-WB-Blog/2020-06-05-imputing-missing-data-for-a-classification-problem/">Imputing missing data for a classification problem</a>
    </h4>
    <div>
        <span>
            
                Karol Saputa;
            
                Małgorzata Wachulec;
            
                Aleksandra Wichrowska;
            
        </span>
    </div>
    <div class="post-meta link-alter">
        <time><i class="fas fa-calendar-day"></i>&nbsp;2020-06-05</time><span><i class="fas fa-file-alt"></i>&nbsp;610 words</span><span><i class="fas fa-tag"></i>&nbsp;<a href="/tags/imputation/">imputation</a> <a href="/tags/missing-data/">missing data</a> </span>
    </div>
    
    
    <div class="post-content markdown-body">
        <h3 id="imputing-missing-data-for-a-classification-problem">Imputing missing data for a classification problem</h3>
<p><em>Authors: Karol Saputa, Małgorzata Wachulec, Aleksandra Wichrowska (Warsaw University of Technology)</em></p>
<p>As students of the same university course, we were asked to sum up the findings of our colleges, the authors of the <em>Default imputation efficiency comparison</em> article. In their work, they used many missing data imputation techniques on 11 datasets, on which they then run different classification algorithms. By measuring the results obtained using these imputation algorithms they could judge their performance. But first:</p>
<h4 id="what-is-data-imputation">What is data imputation?</h4>
<p><img src="/2020L-WB-Blog/2020-06-05-imputing-missing-data-for-a-classification-problem/missing-data.jpg" alt="https://www.dataapplab.com/python_missing_data/missing-data/"></p>
<p>Some datasets have missing values that many classification algorithms cannot handle. One way to make the algorithm work is to delete the observations that include missing data or, if missing values come just from a few columns, we can delete them instead. Unfortunately, this means we might be losing some important piece of information and this is where data imputation comes in - it’s a technique to fill out empty spaces with numerical or categorical values, which should improve significantly the outcome of classification that is run on such dataset.</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Height</th>
<th>Weight</th>
<th>Weight (with mean imputation)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Max</td>
<td>175</td>
<td>60</td>
<td>60</td>
</tr>
<tr>
<td>Frederic</td>
<td>169</td>
<td><strong>NA</strong></td>
<td>70</td>
</tr>
<tr>
<td>Thomas</td>
<td>186</td>
<td>80</td>
<td>80</td>
</tr>
</tbody>
</table>
<p>Table: An example of a dataset with a missing value. NA means a missing value (Not Available)</p>
<p>As we can see in an example above we&rsquo;d like to keep a data point with Frederic instead of deleting it. The simplest way of doing that was to create a new feature where missing values are filled with a mean of all that column values (Weight). Let&rsquo;s see how using different approaches can have an impact on our machine learning model results.</p>
<h4 id="data-imputation-techniques">Data imputation techniques</h4>
<p>Our colleges tried many naive approaches, such as removing columns with missing values, imputing with random values from given feature, or imputing with median (for numerical features) and with mode (for categorical features). They also tried more refined missing data approaches, such as the Random Forest from missForest package, KNN, hot-deck algorithm and Iterative Robust Model-Based Imputation (IRMI) from VIM package, as well as predictive mean matching (pmm) and classification and regression trees (cart) from mice package. This way, they compared a whole spectrum of simple and not-so-simple missing data imputation techniques available in R.</p>
<h4 id="how-the-performance-was-measured">How the performance was measured</h4>
<p>Two factors were considered, time of imputation algorithm consumed and performance gain for a set of machine learning models.</p>
<p><img src="/2020L-WB-Blog/2020-06-05-imputing-missing-data-for-a-classification-problem/time.png" alt="Time of computation, paper results">{ width=80% }</p>
<p>As we can see, the time difference is significant. We can choose between simple, fast methods and slower, more complex ones.</p>
<h5 id="ranking-of-methods-for-each-model">Ranking of methods for each model</h5>
<p>A comparison of imputation methods was done by creating a ranking. Place in the ranking is an average of scores for all datasets (using Weighted TPR-TNR metric) for a specific machine learning model and specific imputation method. Using that methodology, it is possible to compare imputation methods general suitability for using it with ML method.</p>
<h5 id="random-fill-to-get-the-best-results">Random fill to get the best results</h5>
<p><img src="/2020L-WB-Blog/2020-06-05-imputing-missing-data-for-a-classification-problem/ranking.png" alt="Ranking of imputation methods for each model">{ width=80% }</p>
<p><img src="/2020L-WB-Blog/2020-06-05-imputing-missing-data-for-a-classification-problem/ranking_plot.png" alt="Visualisation of paper results">{ height=80% }</p>
<p>Both table and plot show us that filling NAs with random values from that column gives very good results. It is independend of the machine learning model chosen and a fast method to start your work with a new dataset.</p>
<p>However, what is also mentioned in a paper, if you have a big dataset (bigger than used in a paper), there is still a chance that more complex methods will give better results. It is something to try and research in the future.</p>
<h4 id="what-random-generators-are-used-for---random-fil-as-the-best-method">What random generators are used for - random fil as the best method</h4>
<p><img src="/2020L-WB-Blog/2020-06-05-imputing-missing-data-for-a-classification-problem/Dilbert.gif" alt="DILBERT by Scott Adams, https://dilbert.com/strip/2001-10-25"></p>
<h3 id="references">References</h3>
<ol>
<li>Jakub Pingielski, Paulina Przybyłek, Renata Rólkiewicz, Jakub Wiśniewski. (2020) Default imputation efficiency comparison. Warsaw University of Technology
[https://mini-pw.github.io/2020L-WB-Book/default-imputation-efficiency-comparison.html]</li>
</ol>

    </div>
</article>


<div class="license markdown-body">
    <blockquote>
        <p>Unless otherwise noted, the content of this site is licensed under <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)</a>.</p>
    </blockquote>
</div>






            </div>
            
            <div class="col-md-3 col-12 float-left link-alter" id="sidebar">
                

<div class="widget-toc">
    <h5>TOC</h5>
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#imputing-missing-data-for-a-classification-problem">Imputing missing data for a classification problem</a></li>
        <li><a href="#references">References</a></li>
      </ul>
    </li>
  </ul>
</nav>
</div>


<div class="widget-pages">
    <h5>Pages</h5>
    <ul>
        
        
        <li>
            <a href="/2020L-WB-Blog/">Home</a>
        </li>
        
        <li>
            <a href="/2020L-WB-Blog/archives/">Archives</a>
        </li>
        
        <li>
            <a href="/2020L-WB-Blog/about/">About</a>
        </li>
        
    </ul>
</div>

<div class="widget-tags">
    <h5>Tags</h5>
    <div>
        
        <span>
            <a href="/2020L-WB-Blog/tags/automated-regression/">automated regression</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/black-boxes/">black-boxes</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/computer-vision/">computer vision</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/dataset/">dataset</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/embedding/">embedding</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/imputation/">Imputation</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/interpretability/">interpretability</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/machine-learning/">Machine Learning</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/missing-data/">Missing data</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/missings/">missings</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/ml/">ML</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/openml/">OpenML</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/tutorial/">tutorial</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/xai/">XAI</a>
        </span>
        
    </div>
</div>

<div class="widget-links">
    <h5>Links</h5>
    <ul>
        
        <li>
            <a href="https://mini-pw.github.io/2020L-WB-Book/" target="_blank"><span>ML Case Studies Book</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-Reprodukowalnosc" target="_blank"><span>Reproducibility repo (in Polish)</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-Imputacja" target="_blank"><span>Imputation repo (in Polish)</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-InzynieriaCech" target="_blank"><span>Interpretability repo (in Polish)</span></a>
        </li>
        
    </ul>
</div>


            </div>
            
            
            
            <div id="scroll-top">
                <i class="fas fa-chevron-up"></i>
            </div>
            
        </div>
    </main>

    <footer>
    <div class="container-lg text-center">
        <p>&copy; 2020 <a href="/2020L-WB-Blog/"></a> | Powered by <a href="https://github.com/amzrk2/hugo-theme-fuji/" target="_blank">Fuji</a> & <a href="https://gohugo.io/" target="_blank">Hugo</a> </p>
    </div>
    <script src="//yihui.org/js/math-code.js"></script>
<script async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</footer>
    
<script>
    $(function () {
        mediumZoom('.img-zoomable', {
            margin: 32
        });
    });
</script>








<script>
    $('.widget-toc a').click(function () {
        $('html, body').animate({
            scrollTop: $($(this).attr('href')).offset().top
        });
    });
</script>



<script>
    $('#scroll-top').click(function () {
        $('html, body').animate({
            scrollTop: 0
        });
    });
</script>






</body>

</html>
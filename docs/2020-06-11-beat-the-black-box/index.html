<!DOCTYPE html>
<html lang="en">

<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
<meta name="HandheldFriendly" content="True" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<meta name="generator" content="Hugo 0.72.0" />



<link rel="apple-touch-icon" sizes="180x180" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon-16x16.png" />
<link rel="manifest" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/site.webmanifest" />
<link rel="mask-icon" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/safari-pinned-tab.svg" color="#8aa2d3" />
<link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon.ico" />
<meta name="msapplication-TileColor" content="#8aa2d3" />
<meta name="msapplication-config" content="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/browserconfig.xml" />
<meta name="theme-color" content="#ffffff" />



<title>Beat the Black Box! - Machine Learning Case Studies</title>

<meta name="author" content="" />
<meta name="description" content="Understanding things is good for your health There is no doubt we live in a world defined by data. In fact, we always were, only now we&rsquo;ve got a wider variety of tools at our disposal to store and process all this information. We no longer need to search for structures in data by hand, we&rsquo;ve got models and AI for this. However, we still want, or rather feel urge to, understand how all those analysis work. Especially when we&rsquo;re talking about our health data, and that is what authors of &ldquo;Can Automated Regression beat linear model?&quot; are talking about." />

<meta name="keywords" content="interpretability, XAI, automated regression" />

<meta property="og:title" content="Beat the Black Box!" />
<meta property="og:description" content="Understanding things is good for your health There is no doubt we live in a world defined by data. In fact, we always were, only now we&rsquo;ve got a wider variety of tools at our disposal to store and process all this information. We no longer need to search for structures in data by hand, we&rsquo;ve got models and AI for this. However, we still want, or rather feel urge to, understand how all those analysis work. Especially when we&rsquo;re talking about our health data, and that is what authors of &ldquo;Can Automated Regression beat linear model?&quot; are talking about." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/2020L-WB-Blog/2020-06-11-beat-the-black-box/" />
<meta property="og:image" content="/2020L-WB-Blog/img/og.png"/>
<meta property="article:published_time" content="2020-06-11T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-06-11T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/2020L-WB-Blog/img/og.png"/>

<meta name="twitter:title" content="Beat the Black Box!"/>
<meta name="twitter:description" content="Understanding things is good for your health There is no doubt we live in a world defined by data. In fact, we always were, only now we&rsquo;ve got a wider variety of tools at our disposal to store and process all this information. We no longer need to search for structures in data by hand, we&rsquo;ve got models and AI for this. However, we still want, or rather feel urge to, understand how all those analysis work. Especially when we&rsquo;re talking about our health data, and that is what authors of &ldquo;Can Automated Regression beat linear model?&quot; are talking about."/>






<link rel="stylesheet" href="/2020L-WB-Blog/css/main.min.css" />



<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.0/dist/jquery.min.js" integrity="sha256-xNzN2a4ltkB44Mc/Jz3pT4iU1cmeR0FkXs4pru/JxaQ=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.0/lazysizes.min.js" integrity="sha256-h2tMEmhemR2IN4wbbdNjj9LaDIjzwk2hralQwfJmBOE=" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css" integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous" />
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.5/dist/medium-zoom.min.js" integrity="sha256-Jd9xef1tT52aCb+cAqhElj/9D3c99lQvEjyKOuPn3S4=" crossorigin="anonymous"></script>







<body class="d-flex flex-column h-100">
    <header>
    <div class="container-lg clearfix">
        <div class="col-12 link-primary">
            <a class="main-title" href="/2020L-WB-Blog/">Machine Learning Case Studies</a>
            
            <span class="sub-title">by Evidence Based Machine Learning Lab</span>
            
        </div>
    </div>
</header>

    <main>
        <div class="container-lg clearfix">
            
            <div class="col-md-9 col-12 float-left" id="content">
                
<article>
    
    <h4 class="post-title">
        <a href="/2020L-WB-Blog/2020-06-11-beat-the-black-box/">Beat the Black Box!</a>
    </h4>
    <div>
        <span>
            
                Kacper Staroń, Jakub Szypuła;
            
        </span>
    </div>
    <div class="post-meta link-alter">
        <time><i class="fas fa-calendar-day"></i>&nbsp;2020-06-11</time><span><i class="fas fa-file-alt"></i>&nbsp;809 words</span><span><i class="fas fa-tag"></i>&nbsp;<a href="/tags/interpretability/">interpretability</a> <a href="/tags/xai/">XAI</a> <a href="/tags/automated-regression/">automated regression</a> </span>
    </div>
    
    
    <div class="post-content markdown-body">
        <h2 id="understanding-things-is-good-for-your-health">Understanding things is good for your health</h2>
<p>There is no doubt we live in a world defined by data. In fact, we always were, only now we&rsquo;ve got a wider variety of tools at our disposal to store and process all this information. We no longer need to search for structures in data by hand, we&rsquo;ve got models and AI for this. However, we still want, or rather feel urge to, understand how all those analysis work. Especially when we&rsquo;re talking about our health data, and that is what authors of <a href="https://mini-pw.github.io/2020L-WB-Book/can-automated-regression-beat-linear-model.html">&ldquo;Can Automated Regression beat linear model?&quot;</a> are talking about.</p>
<h2 id="this-models-great-why-would-i-want-another-one">This model&rsquo;s great, why would I want another one?</h2>
<p>There is no clear definition of interpretability when it comes to ML models. The one used in Granat&rsquo;s and Maksymiuk&rsquo;s work essentially means that we call the model interpretable if it is possible to determine what contributed to the model&rsquo;s answer. This definition is without a doubt met by Automated Regression, a solution presented in the article as an alternative to H20 AutoML Model. But why would we seek an alternative for based on GBM and performing quite nicely linear regression model?
Because it&rsquo;s the so called black-box. We know the model works for certain data, yet there are crucial parts of the process we can&rsquo;t fully explain while analyzing the model&rsquo;s output. It does not have to be troubling, and it often is accepted as just a part of the solution, however there are times when understanding how every variable contributes to final answer is just as important as the solution itself. I think we can all agree that when it comes to keeping tabs on our health condition, automated diagnosis systems and such, we&rsquo;d like to know that all those complicated algorithms &ldquo;do their job&rdquo; rather than &ldquo;seem to work just fine&rdquo;.
That&rsquo;s why authors decided to compare their model with a black box one to check if interpretable Automated Regression can beat mysterious H20. And what&rsquo;s better dataset for this friendly competition than &ldquo;real high stakes&rdquo; medical data concerning liver disorders?</p>
<h2 id="improve-your-model-in-4-simple-steps">Improve your model in 4 <del>simple</del> steps</h2>
<p>The authors went on to explain how they could increase the efficiency of their model. It consisted of 4 separate stages, that we won&rsquo;t describe. After all, it&rsquo;s already been written in the article, so there&rsquo;s little point in repeating what has already been said.
Their 4 stage improvement included measuring score with two different loss functions, $$L_{0}$$ and $$L_{R}$$. What it means is pretty much &ldquo;the lower the score, the better&rdquo;. Other than that, they further subdivided the results with regard to feature concatenation. At first, it wasn&rsquo;t much of a difference, but boy, did it make difference in latter stages.
[14:54]</p>
<h2 id="but-were-they-able-to-beat-the-black-box">But were they able to Beat the Black Box?</h2>
<p>Yes, they were! But was it a complete victory? Well, for the most part.
The aforementioned loss function showed, that their baseline had already been better than the black box. There&rsquo;s one important question though. Is this loss that is the sole metric by which we can measure success? Well, not exactly, as mentioned by the authors, there&rsquo;s also the variance explained by the model. Also, there&rsquo;s no reason to just say &ldquo;ah yes, it&rsquo;s 1.7% better&rdquo; and call it a day. So they did the 4-stages improvement and the results are below.</p>
<table>
<thead>
<tr>
<th align="center">Model</th>
<th align="center">Baseline</th>
<th align="center">Stage 1</th>
<th align="center">Stage 2</th>
<th align="center">Stage 3</th>
<th align="center">Stage 4</th>
<th align="center">Black-Box</th>
<th align="center">R squared</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">$$L_{0}$$ | With concat.</td>
<td align="center">2.680</td>
<td align="center">2.660</td>
<td align="center">2.613</td>
<td align="center">2.594</td>
<td align="center">2.533</td>
<td align="center">2.727</td>
<td align="center">0.193</td>
</tr>
<tr>
<td align="center">$$L_{R}$$ | With concat.</td>
<td align="center">2.680</td>
<td align="center">2.660</td>
<td align="center">2.613</td>
<td align="center">2.670</td>
<td align="center">2.734</td>
<td align="center">2.727</td>
<td align="center">0.231</td>
</tr>
<tr>
<td align="center">$$L_{0}$$ | Without concat.</td>
<td align="center">2.680</td>
<td align="center">2.660</td>
<td align="center">2.613</td>
<td align="center">2.594</td>
<td align="center">-</td>
<td align="center">2.727</td>
<td align="center">0.171</td>
</tr>
<tr>
<td align="center">$$L_{R}$$ | Without concat.</td>
<td align="center">2.680</td>
<td align="center">2.660</td>
<td align="center">2.613</td>
<td align="center">2.670</td>
<td align="center">-</td>
<td align="center">2.727</td>
<td align="center">0.193</td>
</tr>
</tbody>
</table>
<p>The score going down can be described with a scientific term &ldquo;nice&rdquo;, and it going up as &ldquo;bad&rdquo;, while it going up again to surpass the black-box would be &ldquo;pretty bad&rdquo;. But it&rsquo;s hard to tell how &ldquo;bad&rdquo; it actually is, since it somewhat balances with the &ldquo;pretty nice&rdquo; score of the $$L_{0}$$ function for stage 4. This trade-off is pretty complicated and probably it depends whether it&rsquo;s &ldquo;nice&rdquo; or &ldquo;bad&rdquo;
But none the less, save for one score being 0.25% worse, the Automated Regression proves to be better than the black box for this task. As authors note, it&rsquo;s still unproven for the larger datasets, but they look forward to large dataset extension. In my opinion, it&rsquo;s good that the interpretable model won with the non-interpretable one, especially when it comes to the medical field. It just feels safer, since, unlike the black box, we know *why* it diagnosed the patient. Imagine if the patient would ask &ldquo;doctor, why was I diagnosed&rdquo;, and the doctor said &ldquo;well I don&rsquo;t know I&rsquo;m not the algorithm haha&rdquo;.
To sum it all up:
Yes, they beat the black box. And I hope they beat it again in the future.</p>

    </div>
</article>


<div class="license markdown-body">
    <blockquote>
        <p>Unless otherwise noted, the content of this site is licensed under <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)</a>.</p>
    </blockquote>
</div>






            </div>
            
            <div class="col-md-3 col-12 float-left link-alter" id="sidebar">
                

<div class="widget-toc">
    <h5>TOC</h5>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#understanding-things-is-good-for-your-health">Understanding things is good for your health</a></li>
    <li><a href="#this-models-great-why-would-i-want-another-one">This model&rsquo;s great, why would I want another one?</a></li>
    <li><a href="#improve-your-model-in-4-simple-steps">Improve your model in 4 simple steps</a></li>
    <li><a href="#but-were-they-able-to-beat-the-black-box">But were they able to Beat the Black Box?</a></li>
  </ul>
</nav>
</div>


<div class="widget-pages">
    <h5>Pages</h5>
    <ul>
        
        
        <li>
            <a href="/2020L-WB-Blog/">Home</a>
        </li>
        
        <li>
            <a href="/2020L-WB-Blog/archives/">Archives</a>
        </li>
        
        <li>
            <a href="/2020L-WB-Blog/about/">About</a>
        </li>
        
    </ul>
</div>

<div class="widget-tags">
    <h5>Tags</h5>
    <div>
        
        <span>
            <a href="/2020L-WB-Blog/tags/automated-regression/">automated regression</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/black-boxes/">black-boxes</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/computer-vision/">computer vision</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/dataset/">dataset</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/embedding/">embedding</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/imputation/">Imputation</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/interpretability/">interpretability</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/machine-learning/">Machine Learning</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/missing-data/">Missing data</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/missings/">missings</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/ml/">ML</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/openml/">OpenML</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/tutorial/">tutorial</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/xai/">XAI</a>
        </span>
        
    </div>
</div>

<div class="widget-links">
    <h5>Links</h5>
    <ul>
        
        <li>
            <a href="https://mini-pw.github.io/2020L-WB-Book/" target="_blank"><span>ML Case Studies Book</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-Reprodukowalnosc" target="_blank"><span>Reproducibility repo (in Polish)</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-Imputacja" target="_blank"><span>Imputation repo (in Polish)</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-InzynieriaCech" target="_blank"><span>Interpretability repo (in Polish)</span></a>
        </li>
        
    </ul>
</div>


            </div>
            
            
            
            <div id="scroll-top">
                <i class="fas fa-chevron-up"></i>
            </div>
            
        </div>
    </main>

    <footer>
    <div class="container-lg text-center">
        <p>&copy; 2020 <a href="/2020L-WB-Blog/"></a> | Powered by <a href="https://github.com/amzrk2/hugo-theme-fuji/" target="_blank">Fuji</a> & <a href="https://gohugo.io/" target="_blank">Hugo</a> </p>
    </div>
    <script src="//yihui.org/js/math-code.js"></script>
<script async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</footer>
    
<script>
    $(function () {
        mediumZoom('.img-zoomable', {
            margin: 32
        });
    });
</script>








<script>
    $('.widget-toc a').click(function () {
        $('html, body').animate({
            scrollTop: $($(this).attr('href')).offset().top
        });
    });
</script>



<script>
    $('#scroll-top').click(function () {
        $('html, body').animate({
            scrollTop: 0
        });
    });
</script>






</body>

</html>
<!DOCTYPE html>
<html lang="en">

<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
<meta name="HandheldFriendly" content="True" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
<meta name="generator" content="Hugo 0.72.0" />



<link rel="apple-touch-icon" sizes="180x180" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon-16x16.png" />
<link rel="manifest" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/site.webmanifest" />
<link rel="mask-icon" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/safari-pinned-tab.svg" color="#8aa2d3" />
<link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/favicon.ico" />
<meta name="msapplication-TileColor" content="#8aa2d3" />
<meta name="msapplication-config" content="https://cdn.jsdelivr.net/gh/amzrk2/poal-jsdelivr@1.2.0/favicons/browserconfig.xml" />
<meta name="theme-color" content="#ffffff" />



<title>Explainable Computer Vision - Machine Learning Case Studies</title>

<meta name="author" content="" />
<meta name="description" content="What is this blog entry about? Black-boxes are commonly used in computer vision. But do we have to use it? This article looks at this issue and we try to understand it with our small (but developed after one semester of machine learning experience) brains and summarize it here.
What is this article about? Computer vision is cool. But it would be just as cool to understand how it works, and it&rsquo;s not so obvious. Explainable methods of image recognition - which is de facto classification - cannot use logistic regression and decision trees, because every model loses transparency as its performance increases - not to mention understanding neural networks." />

<meta name="keywords" content="interpretability, ML, computer vision, embedding" />

<meta property="og:title" content="Explainable Computer Vision" />
<meta property="og:description" content="What is this blog entry about? Black-boxes are commonly used in computer vision. But do we have to use it? This article looks at this issue and we try to understand it with our small (but developed after one semester of machine learning experience) brains and summarize it here.
What is this article about? Computer vision is cool. But it would be just as cool to understand how it works, and it&rsquo;s not so obvious. Explainable methods of image recognition - which is de facto classification - cannot use logistic regression and decision trees, because every model loses transparency as its performance increases - not to mention understanding neural networks." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/2020L-WB-Blog/2020-06-09-explainable-computer-vision/" />
<meta property="og:image" content="/2020L-WB-Blog/img/og.png"/>
<meta property="article:published_time" content="2020-06-09T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-06-09T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/2020L-WB-Blog/img/og.png"/>

<meta name="twitter:title" content="Explainable Computer Vision"/>
<meta name="twitter:description" content="What is this blog entry about? Black-boxes are commonly used in computer vision. But do we have to use it? This article looks at this issue and we try to understand it with our small (but developed after one semester of machine learning experience) brains and summarize it here.
What is this article about? Computer vision is cool. But it would be just as cool to understand how it works, and it&rsquo;s not so obvious. Explainable methods of image recognition - which is de facto classification - cannot use logistic regression and decision trees, because every model loses transparency as its performance increases - not to mention understanding neural networks."/>






<link rel="stylesheet" href="/2020L-WB-Blog/css/main.min.css" />



<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.0/dist/jquery.min.js" integrity="sha256-xNzN2a4ltkB44Mc/Jz3pT4iU1cmeR0FkXs4pru/JxaQ=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.0/lazysizes.min.js" integrity="sha256-h2tMEmhemR2IN4wbbdNjj9LaDIjzwk2hralQwfJmBOE=" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css" integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ=" crossorigin="anonymous" />
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.5/dist/medium-zoom.min.js" integrity="sha256-Jd9xef1tT52aCb+cAqhElj/9D3c99lQvEjyKOuPn3S4=" crossorigin="anonymous"></script>







<body class="d-flex flex-column h-100">
    <header>
    <div class="container-lg clearfix">
        <div class="col-12 link-primary">
            <a class="main-title" href="/2020L-WB-Blog/">Machine Learning Case Studies</a>
            
            <span class="sub-title">by Evidence Based Machine Learning Lab</span>
            
        </div>
    </div>
</header>

    <main>
        <div class="container-lg clearfix">
            
            <div class="col-md-9 col-12 float-left" id="content">
                
<article>
    
    <h4 class="post-title">
        <a href="/2020L-WB-Blog/2020-06-09-explainable-computer-vision/">Explainable Computer Vision</a>
    </h4>
    <div>
        <span>
            
                Zuzanna Mróz;
            
                Aleksander Podsiad;
            
                Michał Wdowski;
            
        </span>
    </div>
    <div class="post-meta link-alter">
        <time><i class="fas fa-calendar-day"></i>&nbsp;2020-06-09</time><span><i class="fas fa-file-alt"></i>&nbsp;510 words</span><span><i class="fas fa-tag"></i>&nbsp;<a href="/tags/interpretability/">interpretability</a> <a href="/tags/ml/">ML</a> <a href="/tags/computer-vision/">computer vision</a> <a href="/tags/embedding/">embedding</a> </span>
    </div>
    
    
    <div class="post-content markdown-body">
        <h2 id="what-is-this-blog-entry-about">What is this blog entry about?</h2>
<p>Black-boxes are commonly used in computer vision. But do we have to use it? <a href="https://mini-pw.github.io/2020L-WB-Book/explainable-computer-vision-with-embedding-and-k-nn-classifier.html">This</a> article looks at this issue and we try to understand it with our small (but developed after one semester of machine learning experience) brains and summarize it here.</p>
<h2 id="what-is-this-article-about">What is this article about?</h2>
<p>Computer vision is cool. But it would be just as cool to understand how it works, and it&rsquo;s not so obvious. Explainable methods of image recognition - which is <em>de facto</em> classification - cannot use logistic regression and decision trees, because every model loses transparency as its performance increases - not to mention understanding neural networks. That&rsquo;s why the authors stated that the best for research will be <em>good ol’</em> k-NN, which uses grouping of the most similar results. However, there is a problem with how to measure this similarity of images.</p>
<h2 id="b-but-how">B-but how?</h2>
<p>The solution to the aforementioned problem applied by the authors is <strong>embedding</strong>. But what does that even mean? The simplest way to explain it is to reduce the dimensions of images and present their content in a way that is understandable to the computer.</p>
<p><img src="/2020L-WB-Blog/2020-06-09-explainable-computer-vision/picrel1.png" alt="Diagram showing the purpose and place of embedders in predictions"></p>
<p>In the article, the authors present several different methods by which you can approach the problem of teaching models to recognize images. The aim here was to compare their chosen model with a more advanced and thus less interpretable model. Embedders were used for the selected k-NN:</p>
<ul>
<li>convolutional - actually it&rsquo;s another black-box, so  it’s no use writing about it</li>
<li>SVD - it is some kind of linear transformation by an array of the largest eigenvectors</li>
<li>K-means - the algorithm is executed, and then the centroids chosen by it are used</li>
</ul>
<p>The output model used as a basis for comparing the results is the Convolutional Neural Network (another black box).
To compare the results, the authors used the ACC (accuracy) measure, which is the ratio of correctly matched images to all of them. There is no need to use more complicated metrics, because the data set has been prepared in such a way that separate classes are equal, providing the possibility of simple measurement of model performance.</p>
<h2 id="yes-and">Yes, and?</h2>
<table>
<thead>
<tr>
<th>Model</th>
<th>ACC</th>
</tr>
</thead>
<tbody>
<tr>
<td>Black-Box Convolutional</td>
<td>0.941</td>
</tr>
<tr>
<td>k-NN Convolutional</td>
<td>0.923</td>
</tr>
<tr>
<td>k-NN base</td>
<td>0.8606</td>
</tr>
<tr>
<td>k-NN K-means</td>
<td>0.8512</td>
</tr>
<tr>
<td>Logistic regression</td>
<td>0.847</td>
</tr>
<tr>
<td>k-NN SVD</td>
<td>0.8001</td>
</tr>
</tbody>
</table>
<p>Black-box was the best, but you have to reckon with that, because sometimes you can&rsquo;t do something as good as the uninterpretable model. The best interpretable model was k-NN with the convolutional embedder, but unfortunately it is also only semi-interpretable. k-NN and k-NN with k-means itself did relatively well, but it turned out that k-NN with SVD conversion had lower results than the base k-NN. This transformation didn&rsquo;t help at all, but even hurt. It should also be noted that in case of using K-means the process was much faster than with the base k-NN. To sum it up: using Convolutional embedder got us second-best results and while it is semi interpretable it is still better than base k-NN and logistic regression which turned out to be not interpretable.</p>

    </div>
</article>


<div class="license markdown-body">
    <blockquote>
        <p>Unless otherwise noted, the content of this site is licensed under <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)</a>.</p>
    </blockquote>
</div>






            </div>
            
            <div class="col-md-3 col-12 float-left link-alter" id="sidebar">
                

<div class="widget-toc">
    <h5>TOC</h5>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#what-is-this-blog-entry-about">What is this blog entry about?</a></li>
    <li><a href="#what-is-this-article-about">What is this article about?</a></li>
    <li><a href="#b-but-how">B-but how?</a></li>
    <li><a href="#yes-and">Yes, and?</a></li>
  </ul>
</nav>
</div>


<div class="widget-pages">
    <h5>Pages</h5>
    <ul>
        
        
        <li>
            <a href="/2020L-WB-Blog/">Home</a>
        </li>
        
        <li>
            <a href="/2020L-WB-Blog/archives/">Archives</a>
        </li>
        
        <li>
            <a href="/2020L-WB-Blog/about/">About</a>
        </li>
        
    </ul>
</div>

<div class="widget-tags">
    <h5>Tags</h5>
    <div>
        
        <span>
            <a href="/2020L-WB-Blog/tags/automated-regression/">automated regression</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/black-boxes/">black-boxes</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/computer-vision/">computer vision</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/dataset/">dataset</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/embedding/">embedding</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/imputation/">Imputation</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/interpretability/">interpretability</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/machine-learning/">Machine Learning</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/missing-data/">Missing data</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/missings/">missings</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/ml/">ML</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/openml/">OpenML</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/tutorial/">tutorial</a>
        </span>
        
        <span>
            <a href="/2020L-WB-Blog/tags/xai/">XAI</a>
        </span>
        
    </div>
</div>

<div class="widget-links">
    <h5>Links</h5>
    <ul>
        
        <li>
            <a href="https://mini-pw.github.io/2020L-WB-Book/" target="_blank"><span>ML Case Studies Book</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-Reprodukowalnosc" target="_blank"><span>Reproducibility repo (in Polish)</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-Imputacja" target="_blank"><span>Imputation repo (in Polish)</span></a>
        </li>
        
        <li>
            <a href="https://github.com/mini-pw/2020L-WarsztatyBadawcze-InzynieriaCech" target="_blank"><span>Interpretability repo (in Polish)</span></a>
        </li>
        
    </ul>
</div>


            </div>
            
            
            
            <div id="scroll-top">
                <i class="fas fa-chevron-up"></i>
            </div>
            
        </div>
    </main>

    <footer>
    <div class="container-lg text-center">
        <p>&copy; 2020 <a href="/2020L-WB-Blog/"></a> | Powered by <a href="https://github.com/amzrk2/hugo-theme-fuji/" target="_blank">Fuji</a> & <a href="https://gohugo.io/" target="_blank">Hugo</a> </p>
    </div>
    <script src="//yihui.org/js/math-code.js"></script>
<script async
src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</footer>
    
<script>
    $(function () {
        mediumZoom('.img-zoomable', {
            margin: 32
        });
    });
</script>








<script>
    $('.widget-toc a').click(function () {
        $('html, body').animate({
            scrollTop: $($(this).attr('href')).offset().top
        });
    });
</script>



<script>
    $('#scroll-top').click(function () {
        $('html, body').animate({
            scrollTop: 0
        });
    });
</script>






</body>

</html>